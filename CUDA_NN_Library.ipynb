{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "fDhNSZ_toMhT",
        "outputId": "5bad9ec8-6ad1-4283-b295-25968028d591"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pycuda'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-34c14b4e982c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoinit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpuarray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgpuarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mskcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pycuda'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pycuda.autoinit\n",
        "import pycuda.gpuarray as gpuarray\n",
        "import skcuda.linalg as linalg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUruQpeWaya-",
        "outputId": "6b4eee13-ad98-4b8e-a40f-e4669d421fdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2024.1.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2023.1.1-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.3)\n",
            "Building wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1-cp310-cp310-linux_x86_64.whl size=661205 sha256=052e6ab81ff1eadb7555e93ecb795f8deaa21cfc097602b0ea25f1a7b8e1de0c\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/34/d2/9a349255a4eca3a486d82c79d21e138ce2ccd90f414d9d72b8\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.3.0 pycuda-2024.1 pytools-2023.1.1\n",
            "Collecting scikit-cuda\n",
            "  Downloading scikit_cuda-0.5.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.8/114.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mako>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from scikit-cuda) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-cuda) (1.23.5)\n",
            "Requirement already satisfied: pycuda>=2016.1 in /usr/local/lib/python3.10/dist-packages (from scikit-cuda) (2024.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako>=1.0.1->scikit-cuda) (2.1.3)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.10/dist-packages (from pycuda>=2016.1->scikit-cuda) (2023.1.1)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda>=2016.1->scikit-cuda) (1.4.4)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda>=2016.1->scikit-cuda) (4.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda>=2016.1->scikit-cuda) (4.5.0)\n",
            "Installing collected packages: scikit-cuda\n",
            "Successfully installed scikit-cuda-0.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda\n",
        "!pip install scikit-cuda\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGcUrpnOdEyd",
        "outputId": "48feb199-3ccd-4e8c-8919-438b5a787bd3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: device_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** compiler output in /tmp/tmp3eua3wuv\n",
            "*** compiler output in /tmp/tmph9g8xmpp\n",
            "[0. 2. 4. 6.]\n",
            "[0. 1. 2. 3.]\n",
            "14.0\n"
          ]
        }
      ],
      "source": [
        "a_gpu = gpuarray.to_gpu(np.array([0, 1, 2, 3]).astype(np.float32))\n",
        "a_doubled = (2*a_gpu).get()\n",
        "a_dot = gpuarray.dot(a_gpu, a_gpu).get()\n",
        "print(a_doubled)\n",
        "print(a_gpu)\n",
        "print(a_dot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVCiFehv5Ha5",
        "outputId": "036ac1d4-564c-4459-bcb1-1f3024674cac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 2 3]]\n",
            "(3, 1)\n",
            "[[ 8]\n",
            " [10]\n",
            " [12]]\n",
            "Label: a; Value: [[1 2 3]]; Grad: 0\n",
            "Label: b; Value: [[4]\n",
            " [5]\n",
            " [6]]; Grad: 0\n",
            "Label: z; Value: [[32]]; Grad: 0\n"
          ]
        }
      ],
      "source": [
        "a = np.array([1, 2, 3]).reshape(1, 3)\n",
        "\n",
        "b = np.array([4, 5, 6]).reshape(3, 1)\n",
        "\n",
        "\n",
        "\n",
        "x = Tensor(a, _label='a')\n",
        "y = Tensor(b, _label='b')\n",
        "print(x)\n",
        "print(y)\n",
        "z = x.dot(y); z._label = 'z'\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5g1CW2q8GfL",
        "outputId": "25271461-926a-4a67-c285-799764351a25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(Label: a; Value: [[1 2 3]]; Grad: [[4 5 6]], Label: b; Value: [[4]\n",
            " [5]\n",
            " [6]]; Grad: [[1]\n",
            " [2]\n",
            " [3]])\n"
          ]
        }
      ],
      "source": [
        "z.grad = 1\n",
        "z.backward()\n",
        "\n",
        "print(z._parent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Fd__gw9CR7YJ"
      },
      "outputs": [],
      "source": [
        "class Tensor:\n",
        "  def __init__(self, value, _parent = None, _op = None, grad = 0, _label = None):\n",
        "    self.value = value\n",
        "    self._parent = _parent\n",
        "    self._op = _op\n",
        "    self.grad = 0\n",
        "    self._label = _label\n",
        "\n",
        "  def __repr__(self):\n",
        "    return f'Label: {self._label}; Value: {self.value}; Grad: {self.grad}'\n",
        "\n",
        "  def __add__(self, other):\n",
        "    v = self.value + other.value\n",
        "    out = Tensor(v, (self, other), '+')\n",
        "    return out\n",
        "\n",
        "  def dot(self, other):\n",
        "    #1-d dot product, nx1 @ 1xn, seperating bc of the backward fn, self and other for dot product is diff than matmul\n",
        "    v = np.dot(self.value, other.value)\n",
        "    out = Tensor(v, (self, other), '.')\n",
        "    def backward():\n",
        "      self.grad = out.grad * other.value.T\n",
        "      other.grad = out.grad * self.value.T\n",
        "    out.backward = backward\n",
        "    return out\n",
        "\n",
        "  def matmul(self, other):\n",
        "    #self = nxd, other = dx1, i.e. self is the weight matrix and other is the input\n",
        "    v = np.matmul(self.value, other.value)\n",
        "    out = Tensor(v, (self, other), '@')\n",
        "    def backward():\n",
        "      self.grad = np.matmul(out.grad, other.value.T)\n",
        "      other.grad= np.matmul(self.value.T, out.grad)\n",
        "    out.backward = backward\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfvB_Mou0MlO"
      },
      "outputs": [],
      "source": [
        "class Dense_Layer:\n",
        "  def __init__(self, input_size, output_size):\n",
        "    self.weights = Tensor(np.random.normal(size=(output_size, input_size)))\n",
        "    self.bias = Tensor(np.zeros((output_size, 1)))\n",
        "\n",
        "  def forward(self, input):\n",
        "    self.input = input\n",
        "    z_pre_bias = self.weights.matmul(input)\n",
        "    z = z_pre_bias + self.bias\n",
        "    return z\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbRKDTgH5Bk2"
      },
      "outputs": [],
      "source": [
        "class Dense(Layer):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    self.weights = np.random.normal(size=(output_size, input_size))\n",
        "    self.bias = np.zeros((output_size, 1))\n",
        "\n",
        "  def forward(self, input):\n",
        "    self.input = input\n",
        "    print(\"forward pass\")\n",
        "    print(f\"self.weights shape: {self.weights.shape}\")\n",
        "    print(f\"input shape: {input.shape}\")\n",
        "    print(f\"input value: {input}\")\n",
        "    pre_act = np.dot(self.weights, input)\n",
        "    pre_act += self.bias\n",
        "    return pre_act\n",
        "\n",
        "  def backward(self, output_gradient, learning_rate, input):\n",
        "    print(\"backward pass\")\n",
        "    print(f\"output_gradient shape: {output_gradient.shape}\")\n",
        "    #print(f\"self.weights.T shape: {self.weights.T.shape}\")\n",
        "    #print(f\"input.T shape: {self.input.T.shape}\")\n",
        "    print(f\"input value: {self.input}\")\n",
        "    weights_gradient = np.matmul(output_gradient, self.input.T)\n",
        "    input_gradient = np.matmul(self.weights.T, output_gradient)\n",
        "    print(f\"weights_gradient shape: {weights_gradient}\")\n",
        "    print(f\"input_gradient shape: {input_gradient}\")\n",
        "    self.weights -= learning_rate * weights_gradient\n",
        "    self.bias -= learning_rate * output_gradient\n",
        "    return input_gradient\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ1ENhvmSTB4",
        "outputId": "b0e6fbdb-12bb-441e-fccf-6da0068d17ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: c; Value: [[14]\n",
            " [14]\n",
            " [14]]; Grad: [[1]\n",
            " [1]\n",
            " [1]]\n",
            "(Label: b; Value: [[1 2 3]\n",
            " [1 2 3]\n",
            " [1 2 3]]; Grad: [[1 2 3]\n",
            " [1 2 3]\n",
            " [1 2 3]], Label: a; Value: [[1]\n",
            " [2]\n",
            " [3]]; Grad: [[3]\n",
            " [6]\n",
            " [9]])\n",
            "@\n"
          ]
        }
      ],
      "source": [
        "a = Tensor(np.array([1, 2, 3]).reshape(3, 1), _label= 'a')\n",
        "b = Tensor(np.array([[1, 2, 3], [1, 2, 3], [1, 2, 3]]).reshape(3, 3), _label= 'b')\n",
        "\n",
        "c = b.matmul(a) ; c._label = 'c'; c.grad = np.array([1, 1, 1]).reshape(3, 1)\n",
        "\n",
        "print(c)\n",
        "c.backward()\n",
        "print(c._parent)\n",
        "print(c._op)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgM7v0OU0nMb",
        "outputId": "07563773-3ee3-464f-b97b-e4335dba78fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.weights = [[1 2 3]\n",
            " [1 2 3]\n",
            " [1 2 3]]\n",
            "forward pass\n",
            "self.weights shape: (3, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[1]\n",
            " [2]\n",
            " [3]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "input value: [[1]\n",
            " [2]\n",
            " [3]]\n",
            "weights_gradient shape: [[1 2 3]\n",
            " [1 2 3]\n",
            " [1 2 3]]\n",
            "input_gradient shape: [[3]\n",
            " [6]\n",
            " [9]]\n"
          ]
        }
      ],
      "source": [
        "def lol():\n",
        "  layer = Dense(3, 3)\n",
        "  input = np.array([1, 2, 3]).reshape(3, 1)\n",
        "  weights = np.array([[1, 2, 3], [1, 2, 3], [1, 2, 3]]).reshape(3, 3)\n",
        "  bias = np.array([0, 0, 0]).reshape(3, 1)\n",
        "\n",
        "  layer.weights = weights\n",
        "  layer.bias = bias\n",
        "\n",
        "  print(f\"self.weights = {layer.weights}\" )\n",
        "\n",
        "  layer.forward(input)\n",
        "\n",
        "  layer.backward(np.array([1, 1, 1]).reshape(3, 1), 1, input)\n",
        "\n",
        "lol()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D22krxe88txJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DataLoader:\n",
        "    def __init__(self, inputs, desired_outputs, batch_size, shuffle=True):\n",
        "        self.inputs = inputs\n",
        "        self.desired_outputs = desired_outputs\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "    def __iter__(self):\n",
        "        # Get the total number of data points\n",
        "        self.n_samples = self.inputs.shape[0]\n",
        "\n",
        "        # Create an array of indices\n",
        "        self.indices = np.arange(self.n_samples)\n",
        "\n",
        "        # Shuffle if required\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        # If all data has been seen, stop the iteration\n",
        "        if len(self.indices) == 0:\n",
        "            raise StopIteration\n",
        "\n",
        "        # Select indices for the current batch\n",
        "        current_indices = self.indices[:self.batch_size]\n",
        "        self.indices = self.indices[self.batch_size:]\n",
        "\n",
        "        # Extract the batch of data\n",
        "        batch_inputs = self.inputs[current_indices].T\n",
        "        batch_outputs = self.desired_outputs[current_indices]\n",
        "\n",
        "        return batch_inputs, batch_outputs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhF2vDRP89KM",
        "outputId": "d4520a0a-416c-4267-fdf7-e1b8aecb8c93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]]\n",
            "Batch inputs: [[0]\n",
            " [0]]\n",
            "Batch outputs: [[0]]\n",
            "Batch inputs: [[1]\n",
            " [0]]\n",
            "Batch outputs: [[1]]\n",
            "Batch inputs: [[0]\n",
            " [1]]\n",
            "Batch outputs: [[1]]\n",
            "Batch inputs: [[1]\n",
            " [1]]\n",
            "Batch outputs: [[0]]\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "inputs = np.reshape(([0, 0], [0, 1], [1, 0], [1 , 1]), (4, 2)) # 100 samples, 10 features each\n",
        "#inputs = inputs.T\n",
        "print(inputs)\n",
        "#inputs = inputs.T\n",
        "desired_outputs = np.reshape((0, 1, 1, 0), (4, 1))  # 100 samples, 1 output each\n",
        "batch_size = 1\n",
        "\n",
        "dataloader = DataLoader(inputs, desired_outputs, batch_size)\n",
        "\n",
        "\n",
        "for batch_inputs, batch_outputs in dataloader:\n",
        "    print(\"Batch inputs:\", batch_inputs)\n",
        "    print(\"Batch outputs:\", batch_outputs)\n",
        "    #test = test_layer.forward(batch_inputs.T)\n",
        "    #print(test)\n",
        "    # Here you can feed the batch_inputs and batch_outputs to your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLcELddaglkj"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "inputs = np.reshape(([0, 0], [0, 1], [1, 0], [1 , 1]), (4, 2)) # 100 samples, 10 features each\n",
        "#inputs = inputs.T\n",
        "desired_outputs = np.reshape((0, 1, 1, 0), (4, 1))  # 100 samples, 1 output each\n",
        "batch_size = 1\n",
        "\n",
        "dataloader = DataLoader(inputs, desired_outputs, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Qtelurn4oU8D"
      },
      "outputs": [],
      "source": [
        "def relu(input):\n",
        "  return np.maximum(input, 0)\n",
        "\n",
        "def relu_prime(input):\n",
        "  return np.where(input > 0, 1, 0)\n",
        "\n",
        "def mse(y_hat, y):\n",
        "  return np.mean(np.power(y_hat - y, 2))\n",
        "\n",
        "def mse_prime(y_hat, y):\n",
        "  return 2 * (y_hat - y) / np.size(y)\n",
        "\n",
        "\n",
        "class Neural_Net:\n",
        "  def __init__ (self, layers):\n",
        "    self.layers = layers\n",
        "\n",
        "  def add_layer (self, layer):\n",
        "    self.layers.append(layer)\n",
        "    return self.layers\n",
        "\n",
        "\n",
        "  def forward(self, input):\n",
        "    for layer in self.layers:\n",
        "      input = layer.forward(input)\n",
        "\n",
        "    return input\n",
        "\n",
        "  def error(self, prediction, real):\n",
        "    return mse(prediction, real)\n",
        "\n",
        "  def backward(self, learning_rate, prediction, real, input):\n",
        "\n",
        "    output_gradient = mse_prime(prediction, real)\n",
        "    print(f\"gradient of error wrt prediction shape {output_gradient.shape}\")\n",
        "\n",
        "    for layer in reversed(self.layers):\n",
        "      output_gradient = layer.backward(output_gradient, learning_rate, input)\n",
        "    return\n",
        "\n",
        "\n",
        "  def train(self, epochs, learning_rate, data_loader):\n",
        "    for _ in range(0, epochs):\n",
        "      error = 0\n",
        "      for input_data, desired_output in data_loader:\n",
        "        #input = input.T\n",
        "        prediction = self.forward(input_data)\n",
        "        error = self.error(prediction, desired_output)\n",
        "        self.backward(learning_rate, prediction, desired_output, input_data)\n",
        "      error /= data_loader.batch_size\n",
        "      print(f\"Error for epoch {_}: {error} \")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cWr91XaPnOPX"
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "  def __init__():\n",
        "    return\n",
        "\n",
        "  def forward():\n",
        "    return\n",
        "\n",
        "  def backward():\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1oYlb_TrpAn1"
      },
      "outputs": [],
      "source": [
        "class Dense(Layer):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    self.weights = np.random.normal(size=(output_size, input_size))\n",
        "    self.bias = np.zeros((output_size, 1))\n",
        "\n",
        "  def forward(self, input):\n",
        "    self.input = input\n",
        "    print(\"forward pass\")\n",
        "    print(f\"self.weights shape: {self.weights.shape}\")\n",
        "    print(f\"input shape: {input.shape}\")\n",
        "    print(f\"input value: {input}\")\n",
        "    pre_act = np.dot(self.weights, input)\n",
        "    pre_act += self.bias\n",
        "    return pre_act\n",
        "\n",
        "  def backward(self, output_gradient, learning_rate, input):\n",
        "    print(\"backward pass\")\n",
        "    print(f\"output_gradient shape: {output_gradient.shape}\")\n",
        "    #print(f\"self.weights.T shape: {self.weights.T.shape}\")\n",
        "    #print(f\"input.T shape: {self.input.T.shape}\")\n",
        "    print(f\"input value: {self.input}\")\n",
        "    weights_gradient = np.matmul(output_gradient, self.input.T)\n",
        "    input_gradient = np.matmul(self.weights.T, output_gradient)\n",
        "    print(f\"weights_gradient shape: {weights_gradient}\")\n",
        "    print(f\"input_gradient shape: {input_gradient}\")\n",
        "    self.weights -= learning_rate * weights_gradient\n",
        "    self.bias -= learning_rate * output_gradient\n",
        "    return input_gradient\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nn91hB2QuCbp"
      },
      "outputs": [],
      "source": [
        "class Activation(Layer):\n",
        "  def __init__(self, activation, act_prime):\n",
        "    self.activation = activation\n",
        "    self.act_prime = act_prime\n",
        "\n",
        "  def forward(self, input):\n",
        "    self.input = input\n",
        "    return self.activation(input)\n",
        "\n",
        "  def backward(self, output_gradient, learning_rate, input):\n",
        "    return self.act_prime(self.input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLF9iq-3udhb"
      },
      "outputs": [],
      "source": [
        "class Relu(Activation):\n",
        "  def __init__(self):\n",
        "    activation = lambda x : relu(x)\n",
        "    act_prime = lambda x : relu_prime(x)\n",
        "    return super().__init__(activation, act_prime)\n",
        "  def backward(self, output_gradient, learning_rate, input):\n",
        "    print(f\"output_gradient shape of relu layer (grad of error wrt activation value): {output_gradient.shape}\")\n",
        "    print(f\"input shape of relu layer (pre-activation_value): {self.input.shape}\")\n",
        "    print(f\"input value: {self.input}\")\n",
        "    return np.multiply(self.act_prime(self.input), output_gradient)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9CShLxrcnnh"
      },
      "outputs": [],
      "source": [
        "layer_list = [\n",
        "    Dense(2, 3),\n",
        "    Relu(),\n",
        "    Dense(3, 1),\n",
        "    Relu()\n",
        "]\n",
        "\n",
        "network = Neural_Net(layer_list)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnUQkD6-nsXN"
      },
      "outputs": [],
      "source": [
        "def lol():\n",
        "  test = Relu()\n",
        "  grad = [1]\n",
        "  print(test.backward())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOJ08EE9dpoh",
        "outputId": "10ecdd8d-586f-4ac2-a859-e5eb3f9ba347"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "Error for epoch 9962: 1.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "Error for epoch 9963: 0.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "Error for epoch 9964: 0.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "Error for epoch 9965: 0.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "Error for epoch 9966: 1.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "Error for epoch 9967: 1.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "Error for epoch 9968: 0.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "Error for epoch 9969: 0.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "Error for epoch 9970: 0.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "Error for epoch 9971: 0.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "Error for epoch 9972: 0.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "Error for epoch 9973: 0.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "Error for epoch 9974: 1.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "Error for epoch 9975: 1.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "Error for epoch 9976: 1.925929944387236e-34 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "Error for epoch 9977: 1.925929944387236e-34 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "Error for epoch 9978: 0.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "Error for epoch 9979: 0.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "Error for epoch 9980: 1.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "Error for epoch 9981: 0.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "Error for epoch 9982: 1.925929944387236e-34 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "Error for epoch 9983: 1.925929944387236e-34 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "Error for epoch 9984: 1.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "Error for epoch 9985: 0.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "Error for epoch 9986: 1.925929944387236e-34 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "Error for epoch 9987: 0.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "Error for epoch 9988: 1.925929944387236e-34 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "Error for epoch 9989: 0.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "Error for epoch 9990: 0.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "Error for epoch 9991: 1.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "Error for epoch 9992: 0.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "Error for epoch 9993: 1.925929944387236e-34 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "Error for epoch 9994: 1.925929944387236e-34 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "Error for epoch 9995: 0.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "Error for epoch 9996: 0.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "Error for epoch 9997: 1.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "Error for epoch 9998: 0.0 \n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.38777878e-17]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [0.07439818]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[ 0.        ]\n",
            " [-0.00562689]\n",
            " [ 0.07439818]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[1.]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.14688832]\n",
            " [ 2.00365257]\n",
            " [-0.41399754]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-1.41069252]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [0.        ]\n",
            " [1.10572056]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.78278329]\n",
            " [-0.52372101]\n",
            " [ 1.10572056]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[0]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "gradient of error wrt prediction shape (1, 1)\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (1, 1)\n",
            "input shape of relu layer (pre-activation_value): (1, 1)\n",
            "input value: [[-0.07666756]]\n",
            "backward pass\n",
            "output_gradient shape: (1, 1)\n",
            "self.weights.T shape: (3, 1)\n",
            "input.T shape: (1, 3)\n",
            "input value: [[0.        ]\n",
            " [1.48555845]\n",
            " [0.61732484]]\n",
            "output_gradient shape of relu layer (grad of error wrt activation value): (3, 1)\n",
            "input shape of relu layer (pre-activation_value): (3, 1)\n",
            "input value: [[-0.92967161]\n",
            " [ 1.48555845]\n",
            " [ 0.61732484]]\n",
            "backward pass\n",
            "output_gradient shape: (3, 1)\n",
            "self.weights.T shape: (2, 3)\n",
            "input.T shape: (1, 2)\n",
            "input value: [[1]\n",
            " [1]]\n",
            "Error for epoch 9999: 0.0 \n"
          ]
        }
      ],
      "source": [
        "network.train(10000, 0.1, dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PyVBXDwTPQw",
        "outputId": "dacd8c3b-0302-462e-e489-ceaf331fb18b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[3],\n",
              "       [4]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dedz = np.array([3, 4]).reshape((-1, 1))\n",
        "\n",
        "dedz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMbLGuEFDbGe",
        "outputId": "ce62fae8-62b8-4cdb-f85f-1da1b2173864"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0]])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ee = np.reshape([1, 0], (2, 1))\n",
        "ee"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6vlpNBuDEnR",
        "outputId": "dc831d9a-a5d9-482f-c823-1bb882e41545"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "forward pass\n",
            "self.weights shape: (3, 2)\n",
            "input shape: (2, 1)\n",
            "input value: [[1]\n",
            " [0]]\n",
            "forward pass\n",
            "self.weights shape: (1, 3)\n",
            "input shape: (3, 1)\n",
            "input value: [[0.        ]\n",
            " [2.00365257]\n",
            " [0.        ]]\n",
            "[[1.]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(network.forward(ee))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6aILfHaTFik",
        "outputId": "e2943cd8-0080-47f7-cdea-4e7d351ca4e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1],\n",
              "       [-2],\n",
              "       [ 3]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXsAa18wDVdz",
        "outputId": "3f457a1b-f5a7-49ac-a7a4-766fbe7813ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0],\n",
              "       [3]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = Relu()\n",
        "test.forward(input)\n",
        "\n",
        "#print(test.weights)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoFIcVbpS7Bt",
        "outputId": "3c291c2a-3002-464d-ddc6-a9eb6cefbe4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.02926184]\n",
            " [1.29131245]]\n"
          ]
        }
      ],
      "source": [
        "egg = test.forward(input)\n",
        "\n",
        "print(egg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY3icPZzTc4E",
        "outputId": "1609de26-7b9b-4f27-8b99-a5c389c7c202"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-25.86732936],\n",
              "       [ 45.24942778],\n",
              "       [-75.12692659]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "back = test.backward(dedz, 1)\n",
        "\n",
        "back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZYhE5h9tgFO",
        "outputId": "735cc6d2-414b-43e4-9c75-eb4c7919e59b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.          0.        ]\n",
            " [ 0.17944571 -0.29869203]\n",
            " [-0.7942206  -0.07382915]\n",
            " [-0.06265169  1.14773829]]\n",
            "[[-2.43544411 -1.90185887]\n",
            " [ 0.06280698  0.42694943]\n",
            " [-0.35160918 -1.0454109 ]]\n",
            "[[1 2 3]]\n",
            "[[-1.59695056  2.99686454]]\n",
            "[[0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "layer = Layer((3, 2))\n",
        "\n",
        "print(layer.weights)\n",
        "\n",
        "test1 = np.array([\n",
        "    [1, 0],\n",
        "    [1, 0],\n",
        "    [1, 0]\n",
        "])\n",
        "\n",
        "print(test)\n",
        "print(input)\n",
        "\n",
        "test_forward = layer.forward(input)\n",
        "\n",
        "print(test_forward)\n",
        "\n",
        "print(layer.derivatives)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vo1oATzz19d6",
        "outputId": "786c02f8-6a57-4353-d7f6-0f4da1288b0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 2 3]]\n",
            "[[-0.66403834 -0.11206623]\n",
            " [ 2.08157846 -0.03151657]\n",
            " [-0.28017265 -0.79555331]]\n",
            "[[1.09003914]\n",
            " [0.97991225]]\n",
            "<class 'tuple'>\n"
          ]
        }
      ],
      "source": [
        "print(input)\n",
        "\n",
        "layer1 = Layer((3, 2))\n",
        "\n",
        "print(layer1.weights)\n",
        "\n",
        "layer2 = Layer((2, 1))\n",
        "\n",
        "print(layer2.weights)\n",
        "\n",
        "layers = (layer1, layer2)\n",
        "\n",
        "print(type(layers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjvHAlP32tkf",
        "outputId": "16195b4d-60a0-4d9e-9c7b-6120cafa5388"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.90582208  0.42139595]\n",
            " [ 1.11286853 -0.71953776]\n",
            " [ 0.55423551  1.96286882]]\n",
            "[[-3.59542501]]\n"
          ]
        }
      ],
      "source": [
        "testNet = Neural_Net(layers)\n",
        "\n",
        "print(testNet.layers[0].weights)\n",
        "\n",
        "test = testNet.forward(input)\n",
        "\n",
        "print(test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
